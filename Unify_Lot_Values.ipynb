{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the input: real_data/150321/img/L8_229_82_150321.tif\n"
     ]
    }
   ],
   "source": [
    "# Imports and settings\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "from osgeo import gdal, ogr\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from utils import (\n",
    "    print_cm, test_class_name_to_train_label, train_label_to_test_class_name, \n",
    "    extract_test_mask, add_label_from_reference_name,\n",
    "    separate_files_by_date, CLASS_NAME_TO_INT, INT_TO_CLASS_NAME)\n",
    "\n",
    "from landsat8 import write_geotiff\n",
    "\n",
    "# Settings\n",
    "mask_by_lot = 'mask_lote_id.pickle'\n",
    "verification_pixels_path = 'mask_lote_by_class.pickle'\n",
    "\n",
    "\n",
    "with open(mask_by_lot, 'rb') as flot:\n",
    "    mask_lot = pickle.load(flot)\n",
    "\n",
    "with open(verification_pixels_path, 'rb') as fverification_pixels:\n",
    "    verification_pixels = pickle.load(fverification_pixels)\n",
    "    \n",
    "# We need projection and GeoTransform\n",
    "data_date = \"150321\"\n",
    "raster_data_path = \"real_data/%s/img/L8_229_82_%s.tif\" % (data_date, data_date)\n",
    "\n",
    "print(\"Reading the input: %s\" % raster_data_path)\n",
    "try:\n",
    "    raster_dataset = gdal.Open(raster_data_path, gdal.GA_ReadOnly)\n",
    "except RuntimeError as e:\n",
    "    report_and_exit(str(e))\n",
    "geo_transform = raster_dataset.GetGeoTransform()\n",
    "proj = raster_dataset.GetProjectionRef()\n",
    "# ##################################\n",
    "\n",
    "homogenize_lot_data_path = 'homogenize_lot_%s.pickle' % (data_date)\n",
    "classified_data_path = 'classifier_predicted_%s.pickle' % data_date\n",
    "\n",
    "with open(classified_data_path, 'rb') as fclassified:\n",
    "    classified_data = pickle.load(fclassified)\n",
    "    classified_data = classified_data['classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_most_repited_value(array):\n",
    "    cter = Counter(array)\n",
    "    return sorted(cter, key=lambda x:cter[x])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lot_ids = np.unique(mask_lot)\n",
    "\n",
    "for lot_id in lot_ids:\n",
    "    # gets the lot isolated\n",
    "    f = (mask_lot == lot_id)\n",
    "    \n",
    "    # gets the lot with predicted values\n",
    "    predicted_lot = classified_data[f]\n",
    "    most_repited_value = get_most_repited_value(predicted_lot)\n",
    "    # homogenizes the lot with the most predicted value\n",
    "    classified_data[f] = most_repited_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification image created: homogenize_by_lote_id_150321.tiff\n"
     ]
    }
   ],
   "source": [
    "with open(homogenize_lot_data_path, 'wb') as fhomogenize:\n",
    "    pickle.dump(classified_data, fhomogenize)\n",
    "output_fname = \"homogenize_by_lote_id_%s.tiff\" % data_date\n",
    "write_geotiff(output_fname, classified_data, geo_transform, proj)\n",
    "print(\"Verification image created: %s\" % output_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for_verification = verification_pixels.nonzero()\n",
    "verification_labels = verification_pixels[for_verification]\n",
    "predicted_labels = classified_data[for_verification]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(verification_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \tMAI\tMAN\t PN\tRAS\tSOJ\tSOR\t\n",
      "MAI\t6223\t1270\t471\t1550\t17019\t272\t\n",
      "MAN\t688\t2231\t781\t  0\t5422\t  0\t\n",
      " PN\t  0\t487\t216\t384\t235\t  0\t\n",
      "RAS\t  0\t  0\t  0\t  0\t  0\t  0\t\n",
      "SOJ\t15910\t6237\t1072\t2555\t67846\t1141\t\n",
      "SOR\t769\t  0\t319\t  0\t2017\t158\t\n"
     ]
    }
   ],
   "source": [
    "classes_labels = [train_label_to_test_class_name(str(int(c)))[:3] for c in np.unique(predicted_labels)]\n",
    "print_cm(cm, classes_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.566809\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification accuracy: %f\" %\n",
    "      metrics.accuracy_score(verification_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        MAI       0.26      0.23      0.25     26805\n",
      "        MAN       0.22      0.24      0.23      9122\n",
      "         PN       0.08      0.16      0.10      1322\n",
      "        RAS       0.00      0.00      0.00         0\n",
      "        SOJ       0.73      0.72      0.72     94761\n",
      "        SOR       0.10      0.05      0.07      3263\n",
      "\n",
      "avg / total       0.58      0.57      0.57    135273\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbigatti/.virtualenvs/satimg/lib/python3.4/site-packages/sklearn/metrics/classification.py:1076: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\\n%s\" %\n",
    "      metrics.classification_report(verification_labels, predicted_labels,\n",
    "                                    target_names=classes_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
