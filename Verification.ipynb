{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the input: real_data/150201/img/L8_229_82_150201.tif\n"
     ]
    }
   ],
   "source": [
    "# Imports and Settings\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from osgeo import gdal, ogr\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from landsat8 import write_geotiff\n",
    "\n",
    "from utils import (\n",
    "    print_cm, test_class_name_to_train_label, train_label_to_test_class_name, \n",
    "    extract_test_mask, add_label_from_reference_name,\n",
    "    separate_files_by_date, CLASS_NAME_TO_INT, INT_TO_CLASS_NAME)\n",
    "\n",
    "\n",
    "verification_vector_data_path = \"real_data/puntos_control/CLASIFICACION_Y_ROI.shp\"\n",
    "verification_pixels_path = 'mask_lote_by_class.pickle'\n",
    "\n",
    "vote_result_file = 'vote_result_after_using_context.pickle'\n",
    "output_fname = \"verification_with_votation_after_using_context.tiff\"\n",
    "\n",
    "# We need projection and GeoTransform\n",
    "data_date = \"150201\"\n",
    "raster_data_path = \"real_data/%s/img/L8_229_82_%s.tif\" % (data_date, data_date)\n",
    "print(\"Reading the input: %s\" % raster_data_path)\n",
    "try:\n",
    "    raster_dataset = gdal.Open(raster_data_path, gdal.GA_ReadOnly)\n",
    "except RuntimeError as e:\n",
    "    report_and_exit(str(e))\n",
    "geo_transform = raster_dataset.GetGeoTransform()\n",
    "proj = raster_dataset.GetProjectionRef()\n",
    "# ##################################\n",
    "\n",
    "with open(vote_result_file, 'rb') as fresult:\n",
    "    votation_result = pickle.load(fresult)\n",
    "\n",
    "with open(verification_pixels_path, 'rb') as fverification:\n",
    "     labeled_pixels = pickle.load(fverification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Esto se hace una sola vez\n",
    "# add_label_from_reference_name(verification_vector_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rows, cols = votation_result.shape\n",
    "# test_ds = extract_test_mask(verification_vector_data_path, rows, cols, geo_transform, proj, 'reference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_band = test_ds.GetRasterBand(1)\n",
    "# labeled_pixels = test_band.ReadAsArray()\n",
    "# with open(verification_pixels_path, 'wb') as fverification:\n",
    "#     pickle.dump(labeled_pixels, fverification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification image created: verification_with_votation_after_using_context.tiff\n"
     ]
    }
   ],
   "source": [
    "write_geotiff(output_fname, labeled_pixels, geo_transform, proj)\n",
    "print(\"Verification image created: %s\" % output_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RASTROJO [6]: 0 test pixels\n",
      "RASTROJO [6]: 2511 predicted pixels\n",
      "ALFA [1]: 0 test pixels\n",
      "ALFA [1]: 0 predicted pixels\n",
      "MAIZ [2]: 26805 test pixels\n",
      "MAIZ [2]: 43116 predicted pixels\n",
      "MONTE [4]: 0 test pixels\n",
      "MONTE [4]: 0 predicted pixels\n",
      "PN [5]: 1322 test pixels\n",
      "PN [5]: 59580996 predicted pixels\n",
      "MANI [3]: 9122 test pixels\n",
      "MANI [3]: 3473 predicted pixels\n",
      "SORGO [8]: 3263 test pixels\n",
      "SORGO [8]: 787 predicted pixels\n",
      "SOJA [7]: 94761 test pixels\n",
      "SOJA [7]: 105333 predicted pixels\n"
     ]
    }
   ],
   "source": [
    "for klass, label in CLASS_NAME_TO_INT.items():\n",
    "    print(\"%s [%i]: %i test pixels\" % (klass, label, labeled_pixels[labeled_pixels==label].shape[0]))\n",
    "    print(\"%s [%i]: %i predicted pixels\" % (klass, label, votation_result[votation_result==label].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for_verification = labeled_pixels.nonzero()\n",
    "verification_labels = labeled_pixels[for_verification]\n",
    "predicted_labels = votation_result[for_verification]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(verification_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \tMAI\tMAN\t PN\tRAS\tSOJ\tSOR\t\n",
      "MAI\t10814\t382\t1081\t1482\t13046\t  0\t\n",
      "MAN\t2222\t1596\t198\t  0\t5106\t  0\t\n",
      " PN\t  0\t487\t290\t384\t161\t  0\t\n",
      "RAS\t  0\t  0\t  0\t  0\t  0\t  0\t\n",
      "SOJ\t13764\t874\t1277\t614\t77614\t618\t\n",
      "SOR\t534\t  0\t319\t  0\t2252\t158\t\n"
     ]
    }
   ],
   "source": [
    "classes_labels = [train_label_to_test_class_name(str(int(c)))[:3] for c in np.unique(predicted_labels)]\n",
    "print_cm(cm, classes_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.668810\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification accuracy: %f\" %\n",
    "      metrics.accuracy_score(verification_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        MAI       0.40      0.40      0.40     26805\n",
      "        MAN       0.48      0.17      0.26      9122\n",
      "         PN       0.09      0.22      0.13      1322\n",
      "        RAS       0.00      0.00      0.00         0\n",
      "        SOJ       0.79      0.82      0.80     94761\n",
      "        SOR       0.20      0.05      0.08      3263\n",
      "\n",
      "avg / total       0.67      0.67      0.66    135273\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbigatti/.virtualenvs/satimg/lib/python3.4/site-packages/sklearn/metrics/classification.py:1076: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\\n%s\" %\n",
    "      metrics.classification_report(verification_labels, predicted_labels,\n",
    "                                    target_names=classes_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
