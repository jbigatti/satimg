{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "A classifier was trained (and pickled) using all the vectors in *data/bccba/VECTOR/Roi_Para_Clasificar/*\n",
    "\n",
    "Now all the image will be classified and the vector in *data/bccba/VECTOR/CLASIFICACION_PuntosControl/* will be used to asses the results.\n",
    "\n",
    "To use that vector, we need to modify it: the classes names are strings and we need to match them with the numer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T20:19:33.799120",
     "start_time": "2016-04-24T20:19:29.901485"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from osgeo import gdal, ogr\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "from landsat8 import write_geotiff\n",
    "\n",
    "gdal.UseExceptions()\n",
    "\n",
    "\n",
    "def print_cm(cm, labels):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    # https://gist.github.com/ClementC/acf8d5f21fd91c674808\n",
    "    columnwidth = max([len(x) for x in labels])\n",
    "    # Print header\n",
    "    print(\" \" * columnwidth, end=\"\\t\")\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\"\\t\")\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"%{0}s\".format(columnwidth) % label1, end=\"\\t\")\n",
    "        for j in range(len(labels)):\n",
    "            print(\"%{0}d\".format(columnwidth) % cm[i, j], end=\"\\t\")\n",
    "        print()\n",
    "\n",
    "\n",
    "# ###############################################\n",
    "# Starts testing code\n",
    "# ###############################################\n",
    "TEST_TO_TRAIN_CLASS_NAME = {\n",
    "    'MZ': 'MAIZ',\n",
    "    'MN': 'MANI',\n",
    "    'PN': 'PN',\n",
    "    'SJ': 'SOJA',\n",
    "    'SRG': 'SORGO',\n",
    "}\n",
    "\n",
    "def test_class_name_to_train_label(class_name, training_reference):\n",
    "    \"\"\"Convert the test class name to the label assigned to the pixels during training.\"\"\"\n",
    "    # training_reference must be reference dict generated during the training process. \n",
    "    return training_reference[TEST_TO_TRAIN_CLASS_NAME[class_name]]\n",
    "    \n",
    "\n",
    "def extract_test_mask(vector_data_path, geo_transform, projection):\n",
    "    \"\"\"\n",
    "    Rasterize our modified vector.\n",
    "    \"\"\"\n",
    "    data_source = gdal.OpenEx(vector_data_path, gdal.OF_VECTOR)\n",
    "    if data_source is None:\n",
    "        report_and_exit(\"File read failed: %s\", vector_data_path)\n",
    "    layer = data_source.GetLayer(0)\n",
    "    driver = gdal.GetDriverByName('MEM')\n",
    "    target_ds = driver.Create('', cols, rows, 1, gdal.GDT_UInt16)\n",
    "    target_ds.SetGeoTransform(geo_transform)\n",
    "    target_ds.SetProjection(projection)\n",
    "    gdal.RasterizeLayer(target_ds, [1], layer, options=[\"ATTRIBUTE=reference\"])\n",
    "    return target_ds\n",
    "\n",
    "\n",
    "def add_label_from_reference_name(vector_data_path, training_reference):\n",
    "    \"\"\"\n",
    "    Add a new attribute to the given vector file's geometries, converting the test class name in\n",
    "    ROI_E_14_1 to the corresponding training class label.\n",
    "    \n",
    "    NOTE: The given vector file is modified.\n",
    "    \n",
    "    \"\"\"\n",
    "    ds = gdal.OpenEx(vector_data_path, gdal.OF_UPDATE)\n",
    "    if ds is None:\n",
    "        print(\"Open failed.\")\n",
    "        sys.exit(1)\n",
    "    lyr = ds.GetLayer()\n",
    "\n",
    "    lyr.ResetReading()\n",
    "    lyr_defn = lyr.GetLayerDefn()\n",
    "    \n",
    "    new_field_defn = ogr.FieldDefn(\"reference\", ogr.OFTInteger)\n",
    "\n",
    "    if lyr.CreateField ( new_field_defn ) != 0:\n",
    "        raise Error(\"Creating reference_label field failed.\")\n",
    "    \n",
    "    field_roi_e_14_1 = lyr_defn.GetFieldIndex('E_2015')\n",
    "    field_reference_label = lyr_defn.GetFieldIndex('reference')\n",
    "    for feat in lyr:\n",
    "        field_roi = feat.GetField(field_roi_e_14_1)\n",
    "        field_reference = feat.GetField(field_reference_label)\n",
    "        reference_label = test_class_name_to_train_label(field_roi, training_reference)\n",
    "        \n",
    "        feat.SetField(field_reference_label, reference_label)\n",
    "        lyr.SetFeature(feat)\n",
    "    ds = None\n",
    "# ###############################################\n",
    "# End testing code\n",
    "# ###############################################\n",
    "\n",
    "data_date = \"150201\"\n",
    "raster_data_path = \"real_data/150201/img/L8_229_82_%s.tif\" % data_date\n",
    "trained_classifier_path = \"classifier_trained_%s.pickle\" % data_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T20:19:40.381779",
     "start_time": "2016-04-24T20:19:33.801025"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Reading the input: %s\" % raster_data_path)\n",
    "try:\n",
    "    raster_dataset = gdal.Open(raster_data_path, gdal.GA_ReadOnly)\n",
    "except RuntimeError as e:\n",
    "    report_and_exit(str(e))\n",
    "\n",
    "geo_transform = raster_dataset.GetGeoTransform()\n",
    "proj = raster_dataset.GetProjectionRef()\n",
    "bands_data = []\n",
    "for b in range(1, raster_dataset.RasterCount + 1):\n",
    "    band = raster_dataset.GetRasterBand(b)\n",
    "    bands_data.append(band.ReadAsArray())\n",
    "\n",
    "bands_data = np.dstack(bands_data)\n",
    "rows, cols, n_bands = bands_data.shape\n",
    "# A sample is a vector with all the bands data. Each pixel (independent of its position) is a\n",
    "# sample.\n",
    "n_samples = rows * cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T20:19:40.645764",
     "start_time": "2016-04-24T20:19:40.383194"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(trained_classifier_path, 'rb') as trained_classifier_file:\n",
    "    training = pickle.load(trained_classifier_file)\n",
    "\n",
    "classifier = training['classifier']\n",
    "training_reference = training['reference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T20:19:40.750668",
     "start_time": "2016-04-24T20:19:40.648411"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict by chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T20:20:27.105012",
     "start_time": "2016-04-24T20:19:40.754174"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat_pixels = bands_data.reshape((n_samples, n_bands))\n",
    "dpredict = xgb.DMatrix(flat_pixels)\n",
    "result = classifier.predict(dpredict)\n",
    "# result = np.array([])\n",
    "# chunk_size = 100  # Number of rows\n",
    "# chunk_nr = 0\n",
    "# while chunk_nr*chunk_size < rows:\n",
    "#     start = chunk_nr*cols*chunk_size\n",
    "#     end  = start + cols*chunk_size\n",
    "#     chunk = flat_pixels[start: end]\n",
    "#     predicted_chunk = classifier.predict(chunk)\n",
    "#     result = np.concatenate([result, predicted_chunk])\n",
    "#     chunk_nr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T20:20:27.109553",
     "start_time": "2016-04-24T20:20:27.106952"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification = result.reshape((rows, cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T20:20:27.346581",
     "start_time": "2016-04-24T20:20:27.111098"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(classification[5000:6000, 5000:6000], interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T20:20:28.657268",
     "start_time": "2016-04-24T20:20:27.348772"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_fname = \"classification_%s.tiff\" % data_date\n",
    "write_geotiff(output_fname, classification, geo_transform, proj)\n",
    "print(\"Classification created: %s\" % output_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T20:20:28.941129",
     "start_time": "2016-04-24T20:20:28.660898"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "verification_vector_data_path = \"real_data/puntos_control/CLASIFICACION_Y_ROI.shp\"\n",
    "# Esto se hace una sola vez\n",
    "add_label_from_reference_name(verification_vector_data_path, training_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T20:20:29.304311",
     "start_time": "2016-04-24T20:20:28.943620"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_ds = extract_test_mask(verification_vector_data_path, geo_transform, proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T20:20:29.436060",
     "start_time": "2016-04-24T20:20:29.307766"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_band = test_ds.GetRasterBand(1)\n",
    "labeled_pixels = test_band.ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T20:20:30.713633",
     "start_time": "2016-04-24T20:20:29.439582"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_fname = \"verification_%s.tiff\" % data_date\n",
    "write_geotiff(output_fname, labeled_pixels, geo_transform, proj)\n",
    "print(\"Verification image created: %s\" % output_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T20:20:32.468844",
     "start_time": "2016-04-24T20:20:30.716956"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for klass, label in training_reference.items():\n",
    "    print(\"%s [%i]: %i test pixels\" % (klass, label, labeled_pixels[labeled_pixels==label].shape[0]))\n",
    "    print(\"%s [%i]: %i predicted pixels\" % (klass, label, classification[classification==label].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T20:20:32.830725",
     "start_time": "2016-04-24T20:20:32.470485"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for_verification = labeled_pixels.nonzero()\n",
    "verification_labels = labeled_pixels[for_verification]\n",
    "predicted_labels = classification[for_verification]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T20:20:32.952571",
     "start_time": "2016-04-24T20:20:32.834357"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(verification_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T20:20:32.961534",
     "start_time": "2016-04-24T20:20:32.954242"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_classes = sorted(training_reference, key= lambda x: training_reference[x])\n",
    "train_to_test = {train_name: test_name for test_name, train_name in TEST_TO_TRAIN_CLASS_NAME.items()}\n",
    "classes_labels = [train_to_test.get(c, c[:3]) for c in train_classes]\n",
    "print_cm(cm, classes_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T20:20:33.063704",
     "start_time": "2016-04-24T20:20:32.962977"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Classification accuracy: %f\" %\n",
    "      metrics.accuracy_score(verification_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-04-24T20:20:33.232999",
     "start_time": "2016-04-24T20:20:33.065964"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Classification report:\\n%s\" %\n",
    "      metrics.classification_report(verification_labels, predicted_labels,\n",
    "                                    target_names=classes_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
